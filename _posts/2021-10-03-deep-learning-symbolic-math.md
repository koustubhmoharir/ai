---
layout: post
title:  "Paper Notes: Deep Learning for Symbolic Mathematics"
date:   2021-10-03 18:15:00 +0530
categories: papers
tags: 
---
## Paper Details
[PDF Link](https://arxiv.org/pdf/1912.01412.pdf)  
[Code](https://github.com/facebookresearch/SymbolicMathematics)

Authors
- Guillaume Lample
- François Charton

Year of publication: 2019

## Notes

This paper uses a sequence to sequence model to perform function integration and to solve ordinary differential equations.

>
For integration, humans are taught a set of rules (integration by parts, change of variable, etc.), that are not guaranteed to succeed, and Computer Algebra Systems use complex algorithms (Geddes et al., 1992) that explore a large number of specific cases. For instance, the complete description of the Risch algorithm (Risch, 1970) for function integration is more than 100 pages long.

>
For the sake of simplicity, we use seq2seq models, which were shown to be effective at generating trees, e.g. in the context of constituency parsing (Vinyals et al., 2015), where the task is to predict a syntactic parse tree of input sentences.

The authors represent expressions as trees. The problem of integrating an expression becomes the problem of translating from the original tree to the tree of the solutions. To use a sequence to sequence model, they use standard polish notation (prefix notation) such that $ 2 + 3 \times (5 + 2) $ is represented as the sequence $ +, 2, \times, 3, +, 5, 2 $. This has the benefit of being shorter than prefix notation as it needs no parenthesis. Operators, functions or variables are represented by specific tokens, and integers by sequences of digits preceded by a sign.

The authors generate expression trees randomly and feed them to a symbolic integration tool like Mathematica. One dataset consists of all cases where Mathematica is able to produce an integral. They call this the "forward" dataset. Another method to generate a dataset is to differentiate randomly generated expressions. The integral of the result should be the original expression and this gives a sample data point. They call this the "backward" dataset. However, they note that this process is more likely to favor generation of cases where the integral is simpler than the integrand. Hence they combine this approach with the integration by parts formula to get a more balanced data set for training - "IBP" dataset. They have also taken care to come up with a method for generating random expression trees that produces balanced trees rather than favoring deep trees.

There is a discussion of how to generate ODE solutions that I skipped as I was focusing on the integration of functions.

The authors perform some simplification of expressions to avoid cases like $ x + 1 + 1 + 1 + 1 + 1 $. They use some basic identities for simplification. Full set of identities is not listed. Invalid expressions like $ \sqrt {-2} $ are eliminated by evaluating sub-expressions involving constants and eliminating cases that do not evaluate to finite real numbers.

Expressions are produced with
- up to 15 internal nodes
- leaf nodes may be $x$ or positive and negative integers from 1 to 5
- The binary operators $ +, -, \times, / $
- The functions $ exp, log, sqrt, sin, cos, tan, arcsin, arccos, arctan, sinh, cosh, tanh, arcsinh, arccosh, arctanh $

>
We use a transformer model (Vaswani et al., 2017) with 8 attention heads, 6 layers, and a dimensionality of 512. In our experiences, using larger models did not improve the performance. We train our models with the Adam optimizer (Kingma & Ba, 2014), with a learning rate of $10^{−4}$. We remove expressions with more than 512 tokens, and train our model with 256 equations per batch. At inference, expressions are generated by a beam search (Koehn, 2004; Sutskever et al., 2014), with early stopping. We normalize the log-likelihood scores of hypotheses in the beam by their sequence length. We report results with beam widths of 1 (i.e. greedy decoding), 10 and 50.

It is not clear to me from this description how many neurons or weights this implies. A quick look at the [code](https://github.com/facebookresearch/SymbolicMathematics) for this model suggests that 512 refers to the size of the embeddings and each of the 6 hidden layers contains 2048 neurons. This probably implies at least 25 million weights, not counting the weights for attention heads. However, I am not familiar with ML libraries as of now, and this may not be correct.

When they train their model on a combination of forward, backward and IBP sets, and allow up to 50 attempts, the model is able to produce correct integrals for over 96% cases on held-out cases from the forward set and over 99.5% cases over the backward and IBP sets. Even if the model is limited to just 1 attempt, it still achieves over 93% on forward and over 96% on backward and IBP. Mathematica produces integrals for 84% cases on the backward set.

## Critique

[The Use of Deep Learning for Symbolic Integration](https://arxiv.org/pdf/1912.05752) by Ernest Davis is a review and critique of this paper. It notes that most elementary functions do not have integrals that are elementary. The test set considered here is very artificial as it consists of long and complex expressions that happen to have short integrals. Such expressions are quite unlikely to arise in real situations and are not a priority for Computer Algebra systems. The review also notes that as presented, this work depends on a high quality simplifier of expressions to verify the correctness of solutions generated by this model, and since the model will always generate solutions, verification by calculating a derivative of the generated solution followed by subsequent simplification to check equivalence is essential. The review concludes by saying that there is no reason to suppose that a neural network approach will supercede symbolic Computer Algebra systems in the foreseeable future. Rather amusingly, the review author writes 

> 
It goes without saying that LC [the work being reviewed] has no understanding of the significance of an integral or a derivative or even a function or a number. In fact, occasionally, it outputs a solution that is not even a well-formed expression. LC is like the worst possible student in a calculus class: it doesn’t understand the concepts, it doesn’t learned the rules, it has no idea what is the significance of what it is doing, but it has looked at 80 million examples and gotten a feeling of what integrands and their integrals look like

## Related Work

- [ ] Zaremba et al. (2014) use recursive neural networks to simplify complex symbolic expressions. They use tree representations for expressions, but provide the model with problem related information: possible rules for simplification. The neural network is trained to select the best rule.
- [ ] Allamanis et al. (2017) propose a framework called neural equivalence networks to learn semantic representations of algebraic expressions. Typically, a model is trained to map different but equivalent expressions (like the 10 expressions proposed in Table 5) to the same representation. However, they only consider Boolean and polynomial expressions.
- [ ] Arabshahi et al. (2018a;b) used tree-structured neural networks to verify the correctness of given symbolic entities, and to predict missing entries in incomplete mathematical equations. They also showed that these networks could be used to predict whether an expression is a valid solution of a given differential equation
- [ ] Most attempts to use deep networks for mathematics have focused on arithmetic over integers (sometimes over polynomials with integer coefficients). For instance, Kaiser & Sutskever (2015) proposed the Neural-GPU architecture, and train networks to perform additions and multiplications of numbers given in their binary representations. They show that a model trained on numbers with up-to 20 bits can be applied to much larger numbers at test time, while preserving a perfect accuracy.
- [ ] Freivalds & Liepins (2017) proposed an improved version of the Neural-GPU by using hard non-linear activation functions, and a diagonal gating mechanism.
- [ ] Saxton et al. (2019) use LSTMs (Hochreiter & Schmidhuber, 1997) and transformers on a wide range of problems, from arithmetic to simplification of formal expressions. However, they only consider polynomial functions, and the task of differentiation, which is significantly easier than integration.
- [ ] Trask et al. (2018) propose the Neural arithmetic logic units, a new module designed to learn systematic numerical computation, and that can be used within any neural network. Like Kaiser & Sutskever (2015), they show that at inference their model can extrapolate on numbers orders of magnitude larger than the ones seen during training.
